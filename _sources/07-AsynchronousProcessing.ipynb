{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Asynchronous Processing\n",
    "\n",
    "While many parallel applications can be described as maps, some can be more complex.\n",
    "In this section we look at the asynchronous `concurrent.futures` interface,\n",
    "which provides a simple API for ad-hoc parallelism.\n",
    "This is useful for when your computations don't fit a regular pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Executor.submit\n",
    "\n",
    "The `submit` method starts a computation in a separate thread or process and immediately gives us a `Future` object that refers to the result.  At first, the future is pending.  Once the function completes the future is finished. \n",
    "\n",
    "We collect the result of the task with the `.result()` method,\n",
    "which does not return until the results are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from time import sleep\n",
    "\n",
    "def slowadd(a, b, delay=1):\n",
    "    sleep(delay)\n",
    "    return a + b\n",
    "\n",
    "slowadd(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "e = ThreadPoolExecutor()\n",
    "future = e.submit(slowadd, 1, 2)\n",
    "future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "future.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Submit many tasks, receive many futures\n",
    "\n",
    "Because submit returns immediately we can submit many tasks all at once and they will execute in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "results = [slowadd(i, i, delay=1) for i in range(8)]\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "e = ThreadPoolExecutor()\n",
    "futures = [e.submit(slowadd, i, i, delay=1) for i in range(8)]\n",
    "results = [f.result() for f in futures]\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "*  Submit fires off a single function call in the background, returning a future.  \n",
    "*  When we combine submit with a single for loop we recover the functionality of map.  \n",
    "*  When we want to collect our results we replace each of our futures, `f`, with a call to `f.result()`\n",
    "*  We can combine submit with multiple for loops and other general programming to get something more general than map."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercise 7.1\n",
    "\n",
    "Parallelize the following code with e.submit\n",
    "\n",
    "1.  Replace the `results` list with a list called `futures`\n",
    "2.  Replace calls to `slowadd` and `slowsub` with `e.submit` calls on those functions\n",
    "3.  At the end, block on the computation by recreating the `results` list by calling `.result()` on each future in the `futures` list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Extract daily stock data from google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import os  # library to get directory and file paths\n",
    "import tarfile # this module makes possible to read and write tar archives\n",
    "\n",
    "def extract_data(name, where):\n",
    "    datadir = os.path.join(where,name)\n",
    "    if not os.path.exists(datadir):\n",
    "       print(\"Extracting data...\")\n",
    "       tar_path = os.path.join(where, name+'.tgz')\n",
    "       with tarfile.open(tar_path, mode='r:gz') as data:\n",
    "          data.extractall(where)\n",
    "            \n",
    "extract_data('daily-stock','data') # this function call will extract json files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Convert data to pandas DataFrames and save it in hdf5 files\n",
    "\n",
    "[HDF5](https://portal.hdfgroup.org/display/support) is a data model, library, and file format for storing and managing data. This format is widely used and is supported by many languages and platforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os, glob\n",
    "\n",
    "here = os.getcwd()\n",
    "datadir = os.path.join(here,'data','daily-stock')\n",
    "filenames = sorted(glob.glob(os.path.join(datadir, '*.json')))\n",
    "filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sequential version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "%rm data/daily-stock/*.h5\n",
    "\n",
    "def load_parse_store(fn):\n",
    "    \n",
    "    with open(fn) as f:\n",
    "        data = [json.loads(line) for line in f] # load \n",
    "        \n",
    "    df = pd.DataFrame(data) # parse \n",
    "    \n",
    "    out_filename = fn[:-5] + '.h5'\n",
    "    df.to_hdf(out_filename, '/data') # store\n",
    "    print(\"Finished : %s\" % (out_filename.split(os.path.sep)[-1]))\n",
    "    \n",
    "    return True\n",
    "\n",
    "    \n",
    "results = [load_parse_store(file) for file in filenames]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 7.2\n",
    "\n",
    "Parallelize the loop above using `ThreadPoolExecutor` and `map`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Read files and load dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "filenames = sorted(glob.glob(os.path.join('data', 'daily-stock', '*.h5')))\n",
    "series ={}\n",
    "for fn in filenames:\n",
    "    series[fn] = pd.read_hdf(fn)['close']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Application\n",
    "\n",
    "Given our HDF5 files from the last section we want to find the two datasets with the greatest pair-wise correlation.  This forces us to consider all $n\\times(n-1)$ possibilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "results = {}\n",
    "\n",
    "for a in filenames:\n",
    "    for b in filenames:\n",
    "        if a != b:\n",
    "            results[a, b] = series[a].corr(series[b])\n",
    "            \n",
    "((a, b), corr) = max(results.items(), key=lambda kv: kv[1])\n",
    "print(\"%s matches with %s with correlation %f\" % (a, b, corr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We use matplotlib to visually inspect the highly correlated timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(series[a]/series[a].max())\n",
    "plt.plot(series[b]/series[b].max())\n",
    "plt.xticks(visible=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Analysis\n",
    "\n",
    "This computation starts out by loading data from disk. We already know how to parallelize it:\n",
    "\n",
    "```python\n",
    "series = {}\n",
    "for fn in filenames:\n",
    "    series[fn] = pd.read_hdf(fn)['x']\n",
    "```\n",
    "\n",
    "It follows with a doubly nested for loop with an if statement.  \n",
    "\n",
    "```python\n",
    "results = {}\n",
    "for a in filenames:\n",
    "    for b in filenames:\n",
    "        if a != b:\n",
    "            results[a, b] = series[a].corr(series[b])\n",
    "```\n",
    "\n",
    "It *is* possible to solve this problem with `map`, but it requires some cleverness.  Instead we'll learn `submit`, an interface to start individual function calls asynchronously.\n",
    "\n",
    "It finishes with a reduction on small data.  This part is fast enough.\n",
    "\n",
    "```python\n",
    "((a, b), corr) = max(results.items(), key=lambda kv: kv[1])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 7.3\n",
    "- Parallelize pair-wise correlations with `e.submit`\n",
    "- Implement two versions one using Processes, another with Threads by replacing `e` with a ProcessPoolExecutor:\n",
    "\n",
    "#### Threads\n",
    "\n",
    "```python\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "e = ThreadPoolExecutor(4)\n",
    "```\n",
    "\n",
    "#### Processes\n",
    "\n",
    "Be careful, a `ProcessPoolExecutor` does not run in the jupyter notebook cell.\n",
    "You must run your file in a terminal.\n",
    "\n",
    "```python\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "e = ProcessPoolExecutor(4)\n",
    "```\n",
    "\n",
    "- How does performance vary?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Some conclusions about futures\n",
    "----------------------------\n",
    "\n",
    "*  `submit` functions can help us to parallelize more complex applications\n",
    "*  It didn't actually speed up the code very much\n",
    "*  Threads and Processes give some performance differences\n",
    "*  This is not very robust."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_json": true,
   "formats": "ipynb,md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": "0.9",
    "jupytext_version": "1.5.2"
   }
  },
  "kernelspec": {
   "display_name": "big-data",
   "language": "python",
   "name": "big-data"
  },
  "source_map": [
   16,
   25,
   34,
   49,
   61,
   69,
   75,
   85,
   97,
   104,
   114,
   118,
   137,
   143,
   158,
   162,
   191,
   197,
   201,
   212,
   218,
   236,
   240,
   253,
   283,
   308
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 4
}