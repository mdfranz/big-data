{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Dask\n",
    "\n",
    "<img src=\"images/dask_logo.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- process data that doesn't fit into memory by breaking it into blocks and specifying task chains\n",
    "- parallelize execution of tasks across cores and even nodes of a cluster\n",
    "- move computation to the data rather than the other way around, to minimize communication overheads\n",
    "\n",
    "http://dask.pydata.org/en/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-5b3ddc1512f1>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-5b3ddc1512f1>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    import dask-\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import dask-\n",
    "import dask.multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Define two slow functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "\n",
    "def slowinc(x, delay=1):\n",
    "    sleep(delay)\n",
    "    return x + 1\n",
    "\n",
    "def slowadd(x, y, delay=1):\n",
    "    sleep(delay)\n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "x = slowinc(1)\n",
    "y = slowinc(2)\n",
    "z = slowadd(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parallelize with dask.delayed\n",
    "\n",
    "- Functions wrapped by `dask.delayed` don't run immediately, but instead put those functions and arguments into a task graph. \n",
    "- The result is computed separately by calling the `.compute()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from dask import delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x = delayed(slowinc)(1)\n",
    "y = delayed(slowinc)(2)\n",
    "z = delayed(slowadd)(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "z.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dask graph\n",
    "\n",
    "- Contains description of the calculations necessary to produce the result. \n",
    "- The z object is a lazy Delayed object. This object holds everything we need to compute the final result. We can compute the result with .compute() as above or we can visualize the task graph for this value with .visualize()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "z.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parallelize a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "data = list(range(8))\n",
    "\n",
    "results = []\n",
    "\n",
    "for x in data:\n",
    "    y = slowinc(x)\n",
    "    results.append(y)\n",
    "\n",
    "total = sum(results)\n",
    "total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 8.1\n",
    "\n",
    "- Parallelize this by appending the delayed `slowinc` calls to the list `results`.\n",
    "- Display the graph of `total` computation\n",
    "- Compute time elapsed for the computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Decorator\n",
    "\n",
    "It is also common to see the delayed function used as a decorator. Same example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "@dask.delayed\n",
    "def slowinc(x, delay=1):\n",
    "    sleep(delay)\n",
    "    return x + 1\n",
    "\n",
    "@dask.delayed\n",
    "def slowadd(x, y, delay=1):\n",
    "    sleep(delay)\n",
    "    return x + y\n",
    "\n",
    "x = slowinc(1)\n",
    "y = slowinc(2)\n",
    "z = slowadd(x, y)\n",
    "z.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Control flow\n",
    "-  Delay only some functions, running a few of them immediately. This is helpful when those functions are fast and help us to determine what other slower functions we should call. \n",
    "- In the example below we iterate through a list of inputs. If that input is even then we want to call `half`. If the input is odd then we want to call `odd_process`. This iseven decision to call `half` or `odd_process` has to be made immediately (not lazily) in order for our graph-building Python code to proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from random import randint\n",
    "import dask.delayed\n",
    "\n",
    "def half(x):\n",
    "    sleep(1)\n",
    "    return x // 2\n",
    "\n",
    "def odd_process(x):\n",
    "    sleep(1)\n",
    "    return 3*x+1\n",
    "\n",
    "def is_even(x):\n",
    "    return not x % 2\n",
    "\n",
    "data = [randint(0,100) for i in range(8)]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 8.2\n",
    "- Parallelize the sequential code above using dask.delayed\n",
    "- You will need to delay some functions, but not all\n",
    "- Visualize and check the computed result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 8.3\n",
    "- Parallelize the hdf5 conversion from json files\n",
    "- Create a function `convert_to_hdf`\n",
    "- Use dask.compute function on delayed calls of the funtion created list\n",
    "- Is it really  faster as expected ?\n",
    "\n",
    "Hint: Read [Delayed Best Practices](http://dask.pydata.org/en/latest/delayed-best-practices.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # library to get directory and file paths\n",
    "import tarfile # this module makes possible to read and write tar archives\n",
    "\n",
    "def extract_data(name, where):\n",
    "    datadir = os.path.join(where,name)\n",
    "    if not os.path.exists(datadir):\n",
    "       print(\"Extracting data...\")\n",
    "       tar_path = os.path.join(where, name+'.tgz')\n",
    "       with tarfile.open(tar_path, mode='r:gz') as data:\n",
    "          data.extractall(where)\n",
    "            \n",
    "extract_data('daily-stock','data') # this function call will extract json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "here = os.getcwd() # get the current directory\n",
    "filenames = sorted(glob(os.path.join(here,'data', 'daily-stock', '*.json')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def read( fn ):\n",
    "    with open(fn) as f:\n",
    "        return [json.loads(line) for line in f]\n",
    "    \n",
    "def convert(data):\n",
    "    df = pd.DataFrame(data)\n",
    "    out_filename = fn[:-5] + '.h5'\n",
    "    df.to_hdf(out_filename, os.path.join(here,'data'))\n",
    "    return\n",
    "\n",
    "for fn in filenames:  \n",
    "    data = read( fn)\n",
    "    convert(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls data/daily-stock/*.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read multiple files with Dask Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import dask\n",
    "import dask.delayed as delayed\n",
    "import dask.array as da\n",
    "from glob import glob\n",
    "import h5py as h5\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this dataset we have two dimensional field records along time. Every h5 file contains a matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the file from [https://github.com/MMASSD/datasets](https://github.com/MMASSD/datasets/blob/master/fvalues.tgz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "wget https://github.com/MMASSD/datasets/raw/master/fvalues.tgz\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file is a zip archive we need to uncompress and extract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_data('fvalues','.') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You get 1000 h5 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = sorted(glob(\"*.h5\"))\n",
    "filenames[:5], len(filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to plot these fields, we will scale them between 0 to 255 grey levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def scale(x) :\n",
    "    \"Scale field to 0-255 levels\"\n",
    "    return np.uint8(255*(x-np.min(x)) / (np.max(x)-np.min(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a function that read the file and return the scaled field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py as h5\n",
    "def read_frame( filepath ):\n",
    "    \" Create image from the `dataset` of h5 file `filepath` \"\n",
    "    with h5.File(filepath, \"r\") as f:\n",
    "        z = f.get(\"values\")\n",
    "        return scale(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = read_frame( filenames[0])\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image \n",
    "Image.fromarray(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With NumPy we might allocate a big array and then iteratively load images and place them into this array `serial_frames`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "serial_frames = np.empty((1000,*image.shape), dtype=np.uint8)\n",
    "for i, fn in enumerate(filenames):\n",
    "    serial_frames[i, :, :] = read_frame(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, IntSlider\n",
    "\n",
    "def display_sequence(iframe):\n",
    "    return Image.fromarray(serial_frames[iframe,:,:])\n",
    "    \n",
    "interact(display_sequence, \n",
    "         iframe=IntSlider(min=0,\n",
    "                          max=np.shape(serial_frames)[0]-1,\n",
    "                          step=1,\n",
    "                          value=0, \n",
    "                          continuous_update=True));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code above, we read all images and store them in memory. If you have more plots or bigger images it won't fit in your computer memory. You have two options:\n",
    "- Use a bigger computer\n",
    "- Not store all files in memory and read only the file that contains the field you want to display."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use dask to read and display images\n",
    "\n",
    "We can delayed the read function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lazy_read = delayed(read_frame)\n",
    "lazy_frames = [lazy_read(fn) for fn in filenames]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of `serial_frames`, we create an array of delayed tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "lazy_frames = [da.from_delayed(lazy_read,# Construct a small Dask array\n",
    "                          dtype=image.dtype,   # for every lazy value\n",
    "                          shape=image.shape)\n",
    "          for lazy_read in lazy_frames]\n",
    "lazy_frames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_frames = da.stack(lazy_frames[:10], axis=0)  # concatenate arrays along first axis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_frames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_frames = dask_frames.rechunk((10, 257, 257))   \n",
    "dask_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(scale(dask_frames.sum(axis=0).compute()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, IntSlider\n",
    "\n",
    "def display_sequence(iframe):\n",
    "    \n",
    "    return Image.fromarray(dask_frames[iframe,:,:].compute())\n",
    "    \n",
    "interact(display_sequence, \n",
    "         iframe=IntSlider(min=0,\n",
    "                          max=len(dask_frames)-1,\n",
    "                          step=1,\n",
    "                          value=0, \n",
    "                          continuous_update=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everytime you move the slider, it will read the corresponding file and load the frame. That's why you need to wait a little to get your image. You load image one by one and you can handle a very large amount of images.\n",
    "\n",
    "[Delayed best practices](https://docs.dask.org/en/latest/delayed-best-practices.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_json": true,
   "formats": "ipynb,md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": "0.9",
    "jupytext_version": "1.5.2"
   }
  },
  "kernelspec": {
   "display_name": "big-data",
   "language": "python",
   "name": "big-data"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "source_map": [
   16,
   22,
   30,
   39,
   43,
   59,
   70,
   77,
   85,
   95,
   104,
   111,
   119,
   123,
   141,
   149,
   155,
   178,
   184,
   207,
   214,
   224,
   239,
   253,
   274,
   276,
   280,
   289,
   293,
   297,
   303,
   307,
   309,
   313,
   316,
   320,
   325,
   329,
   338,
   343,
   346,
   350,
   357,
   369,
   375,
   381,
   384,
   388,
   397,
   401,
   405,
   410,
   414,
   427,
   433
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 4
}