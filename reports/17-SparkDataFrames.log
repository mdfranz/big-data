Traceback (most recent call last):
  File "/usr/share/miniconda3/lib/python3.8/site-packages/jupyter_cache/executors/utils.py", line 51, in single_nb_execution
    executenb(
  File "/usr/share/miniconda3/lib/python3.8/site-packages/nbclient/client.py", line 1082, in execute
    return NotebookClient(nb=nb, resources=resources, km=km, **kwargs).execute()
  File "/usr/share/miniconda3/lib/python3.8/site-packages/nbclient/util.py", line 74, in wrapped
    return just_run(coro(*args, **kwargs))
  File "/usr/share/miniconda3/lib/python3.8/site-packages/nbclient/util.py", line 53, in just_run
    return loop.run_until_complete(coro)
  File "/usr/share/miniconda3/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/usr/share/miniconda3/lib/python3.8/site-packages/nbclient/client.py", line 535, in async_execute
    await self.async_execute_cell(
  File "/usr/share/miniconda3/lib/python3.8/site-packages/nbclient/client.py", line 827, in async_execute_cell
    self._check_raise_for_error(cell, exec_reply)
  File "/usr/share/miniconda3/lib/python3.8/site-packages/nbclient/client.py", line 735, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply['content'])
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
from pyspark import SparkContext, SparkConf, SQLContext
# The following three lines are not necessary
# in the pyspark shell
conf = SparkConf().setAppName("people").setMaster("local[*]") 
sc = SparkContext(conf=conf)
sc.setLogLevel("ERROR")
sqlContext = SQLContext(sc)
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mModuleNotFoundError[0m                       Traceback (most recent call last)
[0;32m<ipython-input-2-dd84d56cfdf7>[0m in [0;36m<module>[0;34m[0m
[0;32m----> 1[0;31m [0;32mfrom[0m [0mpyspark[0m [0;32mimport[0m [0mSparkContext[0m[0;34m,[0m [0mSparkConf[0m[0;34m,[0m [0mSQLContext[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m      2[0m [0;31m# The following three lines are not necessary[0m[0;34m[0m[0;34m[0m[0;34m[0m[0m
[1;32m      3[0m [0;31m# in the pyspark shell[0m[0;34m[0m[0;34m[0m[0;34m[0m[0m
[1;32m      4[0m [0mconf[0m [0;34m=[0m [0mSparkConf[0m[0;34m([0m[0;34m)[0m[0;34m.[0m[0msetAppName[0m[0;34m([0m[0;34m"people"[0m[0;34m)[0m[0;34m.[0m[0msetMaster[0m[0;34m([0m[0;34m"local[*]"[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m      5[0m [0msc[0m [0;34m=[0m [0mSparkContext[0m[0;34m([0m[0mconf[0m[0;34m=[0m[0mconf[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m

[0;31mModuleNotFoundError[0m: No module named 'pyspark'
ModuleNotFoundError: No module named 'pyspark'

